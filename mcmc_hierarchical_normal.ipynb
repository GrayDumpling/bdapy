{
 "metadata": {
  "name": "",
  "signature": "sha256:73d9e40cfbf7e003c4c9a8bb67a81110731406585b42d0745cc1dd20c2744c6d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# MCMC on Hierarchical Normal Model (BDA 11.6) #"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "% pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.random.seed(13579)\n",
      "\n",
      "# first write down the data\n",
      "data = {'A':np.array([62,60,63,59]),\n",
      "        'B':np.array([63,67,71,64,65,66]),\n",
      "        'C':np.array([68,66,71,67,68,68]),\n",
      "        'D':np.array([56,62,60,61,63,64,63,59]),\n",
      "        }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define sampler for inverse chi-square\n",
      "def r_inv_chisquare(size, df, scale_sq):\n",
      "    return df * scale_sq / np.random.chisquare(df, size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the empirical mean in each group\n",
      "means = {key: data[key].mean() for key in data.keys()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initialize theta and mu parameters\n",
      "thetas = {key: np.random.choice(data[key]) for key in data.keys()}\n",
      "mu = mean(thetas.values())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from pandas import *\n",
      "from scipy import stats\n",
      "\n",
      "# J in the book\n",
      "group_num = len(data)\n",
      "# n in the book\n",
      "num_points = np.sum([len(value) for value in data.values()])\n",
      "\n",
      "num_samples = 400\n",
      "num_chains = 5\n",
      "\n",
      "sub_sample_dfs = []\n",
      "for chain_index in range(num_chains):\n",
      "    samples = defaultdict(list)\n",
      "    for sample_index in range(num_samples):\n",
      "        # sample tau\n",
      "        tauhat_sq = np.sum((np.array(thetas.values()) - mu) ** 2)/(group_num-1)\n",
      "        tau_sq = r_inv_chisquare(1, group_num - 1, tauhat_sq)[0]\n",
      "        # sample sigma\n",
      "        sigmahat_sq = 0\n",
      "        for key in data.keys():\n",
      "            sigmahat_sq += np.sum((data[key] - thetas[key]) ** 2)\n",
      "        sigmahat_sq /= num_points\n",
      "        sigma_sq = r_inv_chisquare(1, num_points, sigmahat_sq)[0]\n",
      "        # sample mu\n",
      "        muhat = np.mean(thetas.values())\n",
      "        mu = np.random.normal(loc=muhat, scale=np.sqrt(tau_sq/group_num))\n",
      "        # sample thetas\n",
      "        for key in data.keys():\n",
      "            precision = 1.0/tau_sq + len(data[key])/sigma_sq\n",
      "            thetahat = (1.0/tau_sq * mu + len(data[key])/sigma_sq * means[key]) / precision\n",
      "            V_theta = 1.0/precision\n",
      "            thetas[key] = np.random.normal(loc=thetahat, scale=np.sqrt(V_theta))\n",
      "        samples['tau'].append(np.sqrt(tau_sq))\n",
      "        samples['sigma'].append(np.sqrt(sigma_sq))\n",
      "        for key in data.keys():\n",
      "            samples['theta_' + key].append(thetas[key])\n",
      "        # compute log joint posterior probability (up to some constant)\n",
      "        log_joint_posterior = np.log(np.sqrt(tau_sq))\n",
      "        for key in data.keys():\n",
      "            log_joint_posterior += stats.norm.logpdf(thetas[key], loc=mu, scale=np.sqrt(tau_sq))\n",
      "            log_joint_posterior += np.sum(stats.norm.logpdf(data[key], loc=thetas[key], scale=sigma_sq))\n",
      "        samples['log_joint'].append(log_joint_posterior)\n",
      "    # take second half of each chain\n",
      "    second_halfs = {key: value[len(value)/2:] for key, value in samples.iteritems()}\n",
      "    # to break second half of each chain into two sequences, define sequence indices accordingly\n",
      "    second_halfs['seq_index'] = \\\n",
      "            np.concatenate([np.repeat(chain_index * 2, len(second_halfs['tau'])/2),\n",
      "                      np.repeat(chain_index * 2 + 1, len(second_halfs['tau']) - len(second_halfs['tau'])/2)])\n",
      "    sub_sample_dfs.append(DataFrame(second_halfs))\n",
      "sample_dfs = pandas.concat(sub_sample_dfs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, Table 11.3 is reproduced!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_dfs.quantile([0.025, 0.25, 0.5, 0.75, 0.975]).transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0.025</th>\n",
        "      <th>0.25</th>\n",
        "      <th>0.5</th>\n",
        "      <th>0.75</th>\n",
        "      <th>0.975</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>log_joint</th>\n",
        "      <td>-93.296394</td>\n",
        "      <td>-80.988733</td>\n",
        "      <td>-76.717656</td>\n",
        "      <td>-72.744445</td>\n",
        "      <td>-66.684987</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>seq_index</th>\n",
        "      <td>  0.000000</td>\n",
        "      <td>  2.000000</td>\n",
        "      <td>  4.500000</td>\n",
        "      <td>  7.000000</td>\n",
        "      <td>  9.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>sigma</th>\n",
        "      <td>  1.834476</td>\n",
        "      <td>  2.176858</td>\n",
        "      <td>  2.413185</td>\n",
        "      <td>  2.680043</td>\n",
        "      <td>  3.497198</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tau</th>\n",
        "      <td>  2.017235</td>\n",
        "      <td>  3.501172</td>\n",
        "      <td>  5.149848</td>\n",
        "      <td>  7.920210</td>\n",
        "      <td> 28.600897</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>theta_A</th>\n",
        "      <td> 58.823410</td>\n",
        "      <td> 60.489765</td>\n",
        "      <td> 61.217785</td>\n",
        "      <td> 62.013382</td>\n",
        "      <td> 63.542208</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>theta_B</th>\n",
        "      <td> 63.786582</td>\n",
        "      <td> 65.157286</td>\n",
        "      <td> 65.859580</td>\n",
        "      <td> 66.513203</td>\n",
        "      <td> 67.791514</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>theta_C</th>\n",
        "      <td> 65.780671</td>\n",
        "      <td> 67.090658</td>\n",
        "      <td> 67.866808</td>\n",
        "      <td> 68.497923</td>\n",
        "      <td> 69.738009</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>theta_D</th>\n",
        "      <td> 59.283937</td>\n",
        "      <td> 60.560360</td>\n",
        "      <td> 61.153360</td>\n",
        "      <td> 61.726783</td>\n",
        "      <td> 62.800756</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "               0.025      0.250      0.500      0.750      0.975\n",
        "log_joint -93.296394 -80.988733 -76.717656 -72.744445 -66.684987\n",
        "seq_index   0.000000   2.000000   4.500000   7.000000   9.000000\n",
        "sigma       1.834476   2.176858   2.413185   2.680043   3.497198\n",
        "tau         2.017235   3.501172   5.149848   7.920210  28.600897\n",
        "theta_A    58.823410  60.489765  61.217785  62.013382  63.542208\n",
        "theta_B    63.786582  65.157286  65.859580  66.513203  67.791514\n",
        "theta_C    65.780671  67.090658  67.866808  68.497923  69.738009\n",
        "theta_D    59.283937  60.560360  61.153360  61.726783  62.800756"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It turns out, however, that some of $\\hat{R}$ values are smaller than 1.0.  Did I do something wrong?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seq_len = num_samples / 4.0\n",
      "W_values = sample_dfs.groupby('seq_index').var(ddof=1).mean(axis=0)\n",
      "B_values = sample_dfs.groupby('seq_index').mean().var(axis=0,ddof=1) * (seq_len)\n",
      "print \"Rhat values:\"\n",
      "print sqrt((seq_len-1.0)/seq_len + 1.0/seq_len * (B_values / W_values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rhat values:\n",
        "log_joint    1.008436\n",
        "sigma        1.014485\n",
        "tau          1.012767\n",
        "theta_A      1.001640\n",
        "theta_B      0.998435\n",
        "theta_C      1.000642\n",
        "theta_D      1.001859\n",
        "dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}